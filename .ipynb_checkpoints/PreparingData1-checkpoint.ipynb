{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import (AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import metrics, linear_model, naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Chargement du fichier dataProjet.csv dans le dataframe df, n'oubliez pas de modifier le chemin \n",
    "#pour tenir compte de l'endroit ou se trouve votre fichier\n",
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#regroupe les modalités des variables rares, pour un seuil donné \n",
    "def regroupe(df, column, seuil):\n",
    "    \n",
    "    #Valeurs les plus communes\n",
    "    ss = pd.DataFrame(data=df[column].value_counts())\n",
    "    selected = ss[column][ss[column]==1]\n",
    "    column_num = df.columns.get_loc(column)\n",
    "    for x in np.array(selected.index) :\n",
    "        for line_num in df[column][df[column]==x].index.values:\n",
    "            df.set_value(line_num, column_num, np.array(selected.index)[0], takeable=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regroupe(df, \"RESOURCE\", 1)\n",
    "regroupe(df, \"RESOURCE\", 2)\n",
    "regroupe(df, \"MGR_ID\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Echantillonnage de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  74.9977112515 %\n",
      "\n",
      "   ACTION  Percentage\n",
      "1   23142   94.165039\n",
      "0    1434    5.834961\n",
      "\n",
      "\n",
      "test 25.0022887485 % \n",
      "\n",
      "   ACTION  Percentage\n",
      "1    7730   94.348834\n",
      "0     463    5.651166\n"
     ]
    }
   ],
   "source": [
    "Y = df.ACTION\n",
    "X = df.drop(['ACTION'], axis=1)\n",
    "\n",
    "# diviser X et Y en training and testing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25,random_state=1)\n",
    "\n",
    "df1 = pd.DataFrame(Y_train.value_counts())\n",
    "df1['Percentage'] = 100*df1['ACTION']/len(Y_train)\n",
    "pr1=100*len(Y_train)/(len(df)+0.0)\n",
    "print 'train ',pr1,'%\\n\\n', df1\n",
    "\n",
    "df2 = pd.DataFrame(Y_test.value_counts())\n",
    "df2['Percentage'] = 100*df2['ACTION']/len(Y_test)\n",
    "pr2=100*len(Y_test)/(len(df)+0.0)\n",
    "print '\\n\\ntest',pr2,'% \\n\\n',df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fonction d'apprentissage avec cross validation et gridsearch sur le premier dataset\n",
    "def performance(X,Y):\n",
    "    kf = StratifiedKFold(Y, n_folds=3, random_state=1)    \n",
    "    gs = GridSearchCV(clf, params, scoring=metric, cv=kf)\n",
    "    gs.fit(X,Y)\n",
    "    return gs\n",
    "\n",
    "#fonction de prédiction sur le dataset de validation\n",
    "def validation(clf1, Xv, Yv):\n",
    "    preds = clf1.predict_proba(Xv)[:,1]\n",
    "    return roc_auc_score(Yv, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les arbres de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CHOIX DU MODELE A UTILISER\n",
    "#Les arbres de décision\n",
    "\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=1)\n",
    "params = {'max_depth':[13],\n",
    "          'min_samples_leaf' : [13]} #pour le gridSearch    \n",
    "metric = 'roc_auc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultat sur l'ensembles des données\n",
      "Resultat d'apprentissage :  0.727143388698 {'max_depth': 13, 'min_samples_leaf': 13}\n",
      "Resultat de validation :  0.758267416226\n"
     ]
    }
   ],
   "source": [
    "Modele_1 = performance(X_train,Y_train)\n",
    "print \"Resultat sur l'ensembles des données\"\n",
    "\n",
    "print \"Resultat d'apprentissage : \",Modele_1.best_score_, Modele_1.best_params_\n",
    "\n",
    "print \"Resultat de validation : \",validation(Modele_1.best_estimator_, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultat sans \"ROLE_TITLE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultat sur l'ensembles des données\n",
      "Resultat d'apprentissage :  0.717632569738 {'max_depth': 13, 'min_samples_leaf': 13}\n",
      "Resultat de validation :  0.779400473318\n"
     ]
    }
   ],
   "source": [
    "var=['RESOURCE', 'MGR_ID', 'ROLE_ROLLUP_1', 'ROLE_ROLLUP_2','ROLE_DEPTNAME', 'ROLE_FAMILY_DESC', 'ROLE_FAMILY', 'ROLE_CODE']\n",
    "Modele_2 = performance(X_train[var],Y_train)\n",
    "print \"Resultat sur l'ensembles des données\"\n",
    "\n",
    "print \"Resultat d'apprentissage : \",Modele_2.best_score_, Modele_2.best_params_\n",
    "\n",
    "print \"Resultat de validation : \",validation(Modele_2.best_estimator_, X_test[var], Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultat sans \"ROLE_CODE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultat sur l'ensembles des données\n",
      "Resultat d'apprentissage :  0.726791956446 {'max_depth': 13, 'min_samples_leaf': 13}\n",
      "Resultat de validation :  0.760928502175\n"
     ]
    }
   ],
   "source": [
    "var=['RESOURCE', 'MGR_ID', 'ROLE_ROLLUP_1', 'ROLE_ROLLUP_2','ROLE_DEPTNAME', 'ROLE_TITLE', 'ROLE_FAMILY_DESC', 'ROLE_FAMILY']\n",
    "Modele_3 = performance(X_train[var],Y_train)\n",
    "print \"Resultat sur l'ensembles des données\"\n",
    "\n",
    "print \"Resultat d'apprentissage : \",Modele_3.best_score_, Modele_3.best_params_\n",
    "\n",
    "print \"Resultat de validation : \",validation(Modele_3.best_estimator_, X_test[var], Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Etape1:\n",
    "    Resultat sur l'ensembles des données\n",
    "    Resultat d'apprentissage :  0.71868130686 {'max_depth': 13, 'min_samples_leaf': 13}\n",
    "    Resultat de validation :  0.779711035795\n",
    "##### Etape2:    \n",
    "    Resultat sur l'ensembles des données\n",
    "    Resultat d'apprentissage :  0.732219923637 {'max_depth': 13, 'min_samples_leaf': 13}\n",
    "    Resultat de validation :  0.770324728485"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## <span style=\"color:#b36c8f\">On supprime la colonne 'ROLE_CODE' et on garde 'ROLE_TITLE' <br/>(celle qui nous donne une meilleure score)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var=['RESOURCE', 'MGR_ID', 'ROLE_ROLLUP_1', 'ROLE_ROLLUP_2','ROLE_DEPTNAME', 'ROLE_TITLE', 'ROLE_FAMILY_DESC', 'ROLE_FAMILY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=9,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1040, n_jobs=4,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modele_RF =RandomForestClassifier(n_estimators=1040, min_samples_split=9, n_jobs=4, random_state=42)\n",
    "%time modele_RF.fit(X_train[var], Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultat d'apprentissage :  0.993991028285\n",
      "Resultat de validation :  0.868803908365\n"
     ]
    }
   ],
   "source": [
    "print \"Resultat d'apprentissage : \",validation(modele_RF, X_train[var], Y_train)\n",
    "print \"Resultat de validation : \",validation(modele_RF, X_test[var], Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Etape1: (n_estimators=1040, min_samples_split=9, n_jobs=4, random_state=42)\n",
    "    Resultat d'apprentissage :  0.994720093891\n",
    "    Resultat de validation :  0.868639336796\n",
    "###### Etape2: (n_estimators=1040, min_samples_split=9, n_jobs=4, random_state=42)   \n",
    "    Resultat d'apprentissage :  0.994073036677\n",
    "    Resultat de validation :  0.867650230931"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "## AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4h 6min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=9,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1040, n_jobs=4,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "          learning_rate=1.0, n_estimators=50, random_state=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modele_RFC = RandomForestClassifier(n_estimators=1000, min_samples_split=9, n_jobs=4, random_state=42)\n",
    "modele_ABC = AdaBoostClassifier(base_estimator = modele_RF, random_state=1, learning_rate=1.0)\n",
    "%time modele_ABC.fit(X_train[var], Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultat d'apprentissage' :  0.999929367014\n",
      "Wall time: 1h 31min 55s\n"
     ]
    }
   ],
   "source": [
    "%time print \"Resultat d'apprentissage' : \",validation(modele_ABC, X_train[var], Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultat de validation :  0.864917616423\n",
      "Wall time: 1h 33min 13s\n"
     ]
    }
   ],
   "source": [
    "%time print \"Resultat de validation : \",validation(modele_ABC, X_test[var], Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Etape1 :\n",
    "##### Resultat de validation  (modele_RFC ):\n",
    "     0.870251104362      (0.999861415912)     \n",
    "##### Resultat de validation  (modele_RF ):\n",
    "     0.869831153482      (0.999853520928)\n",
    "     \n",
    "##### Etape2 :\n",
    "##### Resultat de validation  (modele_RFC ):\n",
    "     0.      (0.)\n",
    "     \n",
    "##### Resultat de validation  (modele_RF ):\n",
    "     0.864917616423      (0.999929367014) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "## ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_samples_leaf=1, min_samples_split=8,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=1020, n_jobs=4,\n",
       "           oob_score=False, random_state=5, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modele_XT =ExtraTreesClassifier(n_estimators=1020, min_samples_split=8, n_jobs=4, random_state=5)\n",
    "%time modele_XT.fit(X_train[var], Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultat d'apprentissage' :  0.995024653443\n",
      "Resultat de validation :  0.859670605394\n"
     ]
    }
   ],
   "source": [
    "print \"Resultat d'apprentissage' : \",validation(modele_XT, X_train[var], Y_train)\n",
    "print \"Resultat de validation : \",validation(modele_XT, X_test[var], Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Etape1 :   (n_estimators=1020, min_samples_split=8, n_jobs=4, random_state=5)\n",
    "    Resultat d'apprentissage :  0.995549263073\n",
    "    Resultat de validation :  0.860228164929\n",
    "#### Etape2 :   (n_estimators=1020, min_samples_split=8, n_jobs=4, random_state=5)\n",
    "    Resultat d'apprentissage :  0.995002128632\n",
    "    Resultat de validation :  0.860286980405"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "## GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 19s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(init=None, learning_rate=0.2, loss='deviance',\n",
       "              max_depth=20, max_features=None, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=9,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=90,\n",
       "              presort='auto', random_state=1, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modele_GB =GradientBoostingClassifier(n_estimators=90, learning_rate=0.20, max_depth=20, min_samples_split=9, random_state=1)\n",
    "%time modele_GB.fit(X_train[var], Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultat d'apprentissage' :  0.999927302867\n",
      "Resultat de validation :  0.849010195614\n"
     ]
    }
   ],
   "source": [
    "print \"Resultat d'apprentissage' : \",validation(modele_GB, X_train[var], Y_train)\n",
    "print \"Resultat de validation : \",validation(modele_GB, X_test[var], Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Etape1 :   (n_estimators=90, learning_rate=0.20, max_depth=20, min_samples_split=9, random_state=1)\n",
    "    Resultat d'apprentissage' :  1.0\n",
    "    Resultat de validation :  0.84932173602\n",
    "##### Etape2 :   (n_estimators=90, learning_rate=0.20, max_depth=20, min_samples_split=9, random_state=1)\n",
    "    Resultat d'apprentissage' :  0.999930331287\n",
    "    Resultat de validation :  0.850811681508"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/><br/><h4><span style=\"color: #c36b0f;\">Selection des variables : Random Forest</span></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MGR_ID', 'ROLE_FAMILY_DESC', 'ROLE_DEPTNAME', 'ROLE_ROLLUP_2', 'ROLE_TITLE', 'RESOURCE']\n"
     ]
    }
   ],
   "source": [
    "#Approche integree\n",
    "def random_forest_selection(X,Y,n_features):\n",
    "    \n",
    "    params = {'max_depth':[13],\n",
    "              'min_samples_leaf' : [13]}\n",
    "    metric = 'roc_auc'\n",
    "    \n",
    "    clf = RandomForestClassifier(random_state=1, n_jobs=4)\n",
    "    gs = GridSearchCV(clf, params, scoring=metric)\n",
    "    gs.fit(X,Y)\n",
    "    bestClf = gs.best_estimator_\n",
    "    rf = bestClf.feature_importances_\n",
    "    \n",
    "    rf=zip(rf,X.columns)\n",
    "    rf=sorted(rf,reverse=True)[:n_features]\n",
    " \n",
    "    return [x[1] for x in rf]\n",
    "\n",
    "rfFeatures = random_forest_selection(X_train[var], Y_train,6)\n",
    "\n",
    "print rfFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color: #c36b0f;\">LogisticRegression</span></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xt : (32769, 10479)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from scipy import sparse\n",
    "\n",
    "#good_features=range(0,15283)\n",
    "Xt=OneHotEncoder().fit_transform(X[['MGR_ID', 'ROLE_DEPTNAME', 'ROLE_FAMILY_DESC', 'ROLE_ROLLUP_2', 'RESOURCE', 'ROLE_TITLE']].astype(str))\n",
    "print \"Xt :\", Xt.shape\n",
    "#Xts=sparse.hstack([Xt[:,j] for j in good_features]).tocsr()\n",
    "#print \"Xts :\", Xts.shape\n",
    "X_train_sparce, X_test_sparce, Y_train_sparce, Y_test_sparce = train_test_split(Xt, Y, test_size=0.25,random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=2.601, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=2.11, max_iter=100, multi_class='ovr',\n",
       "          n_jobs=4, penalty='l2', random_state=1, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modele_LR = linear_model.LogisticRegression(C=2.601, n_jobs=4,intercept_scaling=2.11, random_state=1)\n",
    "modele_LR.fit(X_train_sparce, Y_train_sparce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultat de validation :  0.859862978103\n",
      "Resultat de validation :  0.859862978103\n"
     ]
    }
   ],
   "source": [
    "print \"Resultat de validation : \",validation(modele_LR, X_test_sparce, Y_test_sparce)\n",
    "print \"Resultat de validation :  0.859862978103\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score E1 0.858838666775\n",
      "score E2 0.859513577853\n"
     ]
    }
   ],
   "source": [
    "print \"score E1\",0.858838666775\n",
    "print \"score E2\",0.859513577853"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color: #c36b0f;\">Naive Bayes</span></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=0.041, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modele_NB = naive_bayes.BernoulliNB(alpha=0.041)\n",
    "%time modele_NB.fit(X_train_sparce, Y_train_sparce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultat de validation :  0.839242216379\n",
      "Resultat de validation :  0.839242216379\n"
     ]
    }
   ],
   "source": [
    "print \"Resultat de validation : \",validation(modele_NB, X_test_sparce, Y_test_sparce)\n",
    "print \"Resultat de validation :  0.839242216379\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score E1 0.83560110534\n",
      "score E2 0.837708683176\n"
     ]
    }
   ],
   "source": [
    "print \"score E1\",0.83560110534\n",
    "print \"score E2\",0.837708683176"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 759 ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "sclf = VotingClassifier(estimators=[('NB', modele_NB), ('LR', modele_LR)], voting='soft', \n",
    "                        weights=[1,9.11])\n",
    "\n",
    "%time sclf = sclf.fit(X_train_sparce, Y_train_sparce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultat de validation =  0.861791175723\n",
      "Resultat de validation =  0.861791175723 weights=[1,9.11]\n"
     ]
    }
   ],
   "source": [
    "print \"Resultat de validation = \",validation(sclf, X_test_sparce, Y_test_sparce)\n",
    "print \"Resultat de validation = \",0.861791175723,\"weights=[1,9.11]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_models=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fopt_pred(pars, data):\n",
    "    return np.dot(data, pars)\n",
    "\n",
    "def fopt(pars):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_train, fopt_pred(pars, B_train))\n",
    "    return -metrics.auc(fpr, tpr)\n",
    "\n",
    "x0 = np.ones((n_models, 1)) / n_models\n",
    "xopt = minimize(fopt, x0)\n",
    "preds = fopt_pred(xopt, B_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Soft VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Training classifiers\n",
    "\n",
    "#, ('LR', modele_LR), ('NB', modele_NB)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('DT', Modele_3.best_estimator_), ('RF', modele_RF), ('ABC', modele_ABC), ('XT', modele_XT), ('GB', modele_GB)], voting='soft', \n",
    "                        weights=[1,1,1,1,1])\n",
    "\n",
    "%time eclf = eclf.fit(X_train[var], Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Resultat de validation = \",validation(eclf, X_test[var], Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"E1 weights=[1,4,5,3,2]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "test = pd.read_csv('test.csv', index_col=0)\n",
    "\n",
    "clos=['MGR_ID', 'ROLE_DEPTNAME', 'ROLE_FAMILY_DESC', 'ROLE_ROLLUP_2', 'RESOURCE', 'ROLE_TITLE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtest=OneHotEncoder().fit_transform(test[clos].astype(str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58921, 13403)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected input with 10479 features, got 13403 instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-335-f21e17ed62df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\s-er_000\\Anaconda2\\lib\\site-packages\\sklearn\\ensemble\\voting_classifier.pyc\u001b[0m in \u001b[0;36m_predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_predict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[1;34m\"\"\"Predict class probabilities for X in 'soft' voting \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mavg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_collect_probas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mavg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\s-er_000\\Anaconda2\\lib\\site-packages\\sklearn\\ensemble\\voting_classifier.pyc\u001b[0m in \u001b[0;36m_collect_probas\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_collect_probas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[1;34m\"\"\"Collect results from clf.predict calls. \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_predict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\s-er_000\\Anaconda2\\lib\\site-packages\\sklearn\\naive_bayes.pyc\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mappear\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mattribute\u001b[0m \u001b[1;33m`\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \"\"\"\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_log_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\s-er_000\\Anaconda2\\lib\\site-packages\\sklearn\\naive_bayes.pyc\u001b[0m in \u001b[0;36mpredict_log_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mappear\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mattribute\u001b[0m \u001b[1;33m`\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mjll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[1;31m# normalize by P(x) = P(f_1, ..., f_n)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mlog_prob_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\s-er_000\\Anaconda2\\lib\\site-packages\\sklearn\\naive_bayes.pyc\u001b[0m in \u001b[0;36m_joint_log_likelihood\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features_X\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             raise ValueError(\"Expected input with %d features, got %d instead\"\n\u001b[0;32m--> 783\u001b[0;31m                              % (n_features, n_features_X))\n\u001b[0m\u001b[1;32m    784\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0mneg_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_log_prob_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected input with 10479 features, got 13403 instead"
     ]
    }
   ],
   "source": [
    "preds = sclf.predict_proba(Xtest)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-336-975da50b0de5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msubmissions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ACTION\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'preds' is not defined"
     ]
    }
   ],
   "source": [
    "submissions = pd.DataFrame(data=preds, columns=[\"ACTION\"], index = test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'submissions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-337-c0690171771d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msubmissions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sampleSubmission.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'submissions' is not defined"
     ]
    }
   ],
   "source": [
    "submissions.to_csv(\"sampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Approche filtre\n",
    "def variance_selection(X,n_features):\n",
    "    \n",
    "    variance = [np.var(X.getcol(i).todense()) for i in range(X.shape[1])]\n",
    "    variance = sorted( zip(variance,range(X.shape[1])) ,reverse=True)[:n_features]   \n",
    "        \n",
    "    return [x[1] for x in variance]\n",
    "\n",
    "for n_features in range(1000,X.shape[1],100):\n",
    "    print n_features\n",
    "    good_features = variance_selection(X_train_sparce,n_features)\n",
    "    print 'Selected features : ', good_features\n",
    "    Xts=sparse.hstack([X_train_sparce[:,j] for j in good_features]).tocsr()\n",
    "    gs = performance(Xts, Y_train_sparce)\n",
    "    print gs.best_score_, gs.best_params_\n",
    "    \n",
    "    print '***************************\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
