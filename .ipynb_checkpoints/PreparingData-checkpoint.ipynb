{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import (AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import metrics, linear_model, naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Chargement du fichier dataProjet.csv dans le dataframe df, n'oubliez pas de modifier le chemin \n",
    "#pour tenir compte de l'endroit ou se trouve votre fichier\n",
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of unique values of each column in train set\n",
      "ACTION                 2\n",
      "RESOURCE            7518\n",
      "MGR_ID              4243\n",
      "ROLE_ROLLUP_1        128\n",
      "ROLE_ROLLUP_2        177\n",
      "ROLE_DEPTNAME        449\n",
      "ROLE_TITLE           343\n",
      "ROLE_FAMILY_DESC    2358\n",
      "ROLE_FAMILY           67\n",
      "ROLE_CODE            343\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"Count of unique values of each column in train set\"\n",
    "print df.apply(lambda x: len(x.unique()))\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.RESOURCE.count()*2.5/100 <= np.array(df.MGR_ID.value_counts()==2 ,dtype=int).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "371"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(df.ROLE_FAMILY_DESC.value_counts()==2 ,dtype=int).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#regroupe les modalités des variables rares, pour un seuil donné \n",
    "def regroupe(df, column, seuil):\n",
    "    if (df[column].count()*2.5/100) <= (np.array(df[column].value_counts()==seuil ,dtype=int).sum()):\n",
    "        #Valeurs les plus communes\n",
    "        ss = pd.DataFrame(data=df[column].value_counts())\n",
    "        selected = ss[column][ss[column]==1]\n",
    "        column_num = df.columns.get_loc(column)\n",
    "        for x in np.array(selected.index) :\n",
    "            for line_num in df[column][df[column]==x].index.values:\n",
    "                df.set_value(line_num, column_num, np.array(selected.index)[0], takeable=True)\n",
    "        print column,\"seuil=\",seuil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESOURCE seuil= 1\n",
      "RESOURCE seuil= 2\n",
      "MGR_ID seuil= 1\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns.values:\n",
    "    for i in [1,2,3]:\n",
    "        regroupe(df, col, i)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Echantillonnage de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  74.9977112515 %\n",
      "\n",
      "   ACTION  Percentage\n",
      "1   23142   94.165039\n",
      "0    1434    5.834961\n",
      "\n",
      "\n",
      "test 25.0022887485 % \n",
      "\n",
      "   ACTION  Percentage\n",
      "1    7730   94.348834\n",
      "0     463    5.651166\n"
     ]
    }
   ],
   "source": [
    "Y = df.ACTION\n",
    "X = df.drop(['ACTION'], axis=1)\n",
    "\n",
    "# diviser X et Y en training and testing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25,random_state=1)\n",
    "\n",
    "df1 = pd.DataFrame(Y_train.value_counts())\n",
    "df1['Percentage'] = 100*df1['ACTION']/len(Y_train)\n",
    "pr1=100*len(Y_train)/(len(df)+0.0)\n",
    "print 'train ',pr1,'%\\n\\n', df1\n",
    "\n",
    "df2 = pd.DataFrame(Y_test.value_counts())\n",
    "df2['Percentage'] = 100*df2['ACTION']/len(Y_test)\n",
    "pr2=100*len(Y_test)/(len(df)+0.0)\n",
    "print '\\n\\ntest',pr2,'% \\n\\n',df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fonction d'apprentissage avec cross validation et gridsearch sur le premier dataset\n",
    "def performance(X,Y):\n",
    "    kf = StratifiedKFold(Y, n_folds=3, random_state=1)    \n",
    "    gs = GridSearchCV(clf, params, scoring=metric, cv=kf)\n",
    "    gs.fit(X,Y)\n",
    "    return gs\n",
    "\n",
    "#fonction de prédiction sur le dataset de validation\n",
    "def validation(clf1, Xv, Yv):\n",
    "    preds = clf1.predict_proba(Xv)[:,1]\n",
    "    return roc_auc_score(Yv, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les arbres de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CHOIX DU MODELE A UTILISER\n",
    "#Les arbres de décision\n",
    "\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=1)\n",
    "params = {'max_depth':range(1,15),\n",
    "          'min_samples_leaf' : range(1,15)} #pour le gridSearch    \n",
    "metric = 'roc_auc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultat sur l'ensembles des données\n",
      "Resultat d'apprentissage :  0.728810104181 {'max_depth': 14, 'min_samples_leaf': 14}\n",
      "Resultat de validation :  0.762003246726\n"
     ]
    }
   ],
   "source": [
    "Modele_1 = performance(X_train,Y_train)\n",
    "print \"Resultat sur l'ensembles des données\"\n",
    "\n",
    "print \"Resultat d'apprentissage : \",Modele_1.best_score_, Modele_1.best_params_\n",
    "\n",
    "print \"Resultat de validation : \",validation(Modele_1.best_estimator_, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultat sans \"ROLE_TITLE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultat sur l'ensembles des données\n",
      "Resultat d'apprentissage :  0.717632569738 {'max_depth': 13, 'min_samples_leaf': 13}\n",
      "Resultat de validation :  0.779400473318\n"
     ]
    }
   ],
   "source": [
    "var=['RESOURCE', 'MGR_ID', 'ROLE_ROLLUP_1', 'ROLE_ROLLUP_2','ROLE_DEPTNAME', 'ROLE_FAMILY_DESC', 'ROLE_FAMILY', 'ROLE_CODE']\n",
    "Modele_2 = performance(X_train[var],Y_train)\n",
    "print \"Resultat sur l'ensembles des données\"\n",
    "\n",
    "print \"Resultat d'apprentissage : \",Modele_2.best_score_, Modele_2.best_params_\n",
    "\n",
    "print \"Resultat de validation : \",validation(Modele_2.best_estimator_, X_test[var], Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultat sans \"ROLE_CODE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultat sur l'ensembles des données\n",
      "Resultat d'apprentissage :  0.732219923637 {'max_depth': 13, 'min_samples_leaf': 13}\n",
      "Resultat de validation :  0.770324728485\n"
     ]
    }
   ],
   "source": [
    "var=['RESOURCE', 'MGR_ID', 'ROLE_ROLLUP_1', 'ROLE_ROLLUP_2','ROLE_DEPTNAME', 'ROLE_TITLE', 'ROLE_FAMILY_DESC', 'ROLE_FAMILY']\n",
    "Modele_3 = performance(X_train[var],Y_train)\n",
    "print \"Resultat sur l'ensembles des données\"\n",
    "\n",
    "print \"Resultat d'apprentissage : \",Modele_3.best_score_, Modele_3.best_params_\n",
    "\n",
    "print \"Resultat de validation : \",validation(Modele_3.best_estimator_, X_test[var], Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## <span style=\"color:#b36c8f\">On supprime la colonne 'ROLE_CODE' et on garde 'ROLE_TITLE' <br/>(celle qui nous donne une meilleure score)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var=['RESOURCE', 'MGR_ID', 'ROLE_ROLLUP_1', 'ROLE_ROLLUP_2','ROLE_DEPTNAME', 'ROLE_TITLE', 'ROLE_FAMILY_DESC', 'ROLE_FAMILY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.1 s, sys: 404 ms, total: 31.5 s\n",
      "Wall time: 17.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=9,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1040, n_jobs=2,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modele_RF =RandomForestClassifier(n_estimators=1040, min_samples_split=9, n_jobs=2, random_state=42)\n",
    "%time modele_RF.fit(X_train[var], Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultat d'apprentissage :  0.994073036677\n",
      "Resultat de validation :  0.867650230931\n"
     ]
    }
   ],
   "source": [
    "print \"Resultat d'apprentissage : \",validation(modele_RF, X_train[var], Y_train)\n",
    "print \"Resultat de validation : \",validation(modele_RF, X_test[var], Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "## AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29min 16s, sys: 1min 9s, total: 30min 26s\n",
      "Wall time: 16min 55s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=9,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=2,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "          learning_rate=1.0, n_estimators=50, random_state=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modele_RFC = RandomForestClassifier(n_estimators=1000, min_samples_split=9, n_jobs=2, random_state=42)\n",
    "modele_ABC = AdaBoostClassifier(base_estimator = modele_RFC, random_state=1, learning_rate=1.0)\n",
    "%time modele_ABC.fit(X_train[var], Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultat d'apprentissage' :  0.99992924648\n",
      "CPU times: user 4min 42s, sys: 1min 11s, total: 5min 54s\n",
      "Wall time: 4min 25s\n"
     ]
    }
   ],
   "source": [
    "%time print \"Resultat d'apprentissage' : \",validation(modele_ABC, X_train[var], Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultat de validation :  0.864499481697\n",
      "CPU times: user 2min 9s, sys: 53.1 s, total: 3min 2s\n",
      "Wall time: 2min 44s\n"
     ]
    }
   ],
   "source": [
    "%time print \"Resultat de validation : \",validation(modele_ABC, X_test[var], Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultat de validation  ( n_estimators ):\n",
    "     2000 ==> 0.776515441507\n",
    "     3000 ==> 0.783840133669\n",
    "     5000 ==> 0.797278561829\n",
    "    10000 ==> 0.8089289157\n",
    "    20000 ==> 0.818141151554\n",
    "    30000 ==> 0.82117804185       (0.946997567742)\n",
    "    100000 ==> 0.82720110981      (0.963220976261)\n",
    "    \n",
    "#### Resultat de validation  (modele_RF ,  n_estimators ):\n",
    "     1000 ==> 0.870251104362      (0.999861415912)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RandomForestClassifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "## ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.2 s, sys: 1.1 s, total: 23.3 s\n",
      "Wall time: 14.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_samples_leaf=1, min_samples_split=8,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=1020, n_jobs=2,\n",
       "           oob_score=False, random_state=5, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modele_XT =ExtraTreesClassifier(n_estimators=1020, min_samples_split=8, n_jobs=2, random_state=5)\n",
    "%time modele_XT.fit(X_train[var], Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultat d'apprentissage' : "
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'modele_XT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-255-67f4814ad30f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Resultat d'apprentissage' : \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodele_XT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Resultat de validation : \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodele_XT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'modele_XT' is not defined"
     ]
    }
   ],
   "source": [
    "print \"Resultat d'apprentissage' : \",validation(modele_XT, X_train[var], Y_train)\n",
    "print \"Resultat de validation : \",validation(modele_XT, X_test[var], Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(n_estimators=1020, min_samples_split=8, n_jobs=2, random_state=5)\n",
    "Resultat d'apprentissage' :  0.995549263073\n",
    "Resultat de validation :  0.860228164929"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "## GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.3 s, sys: 140 ms, total: 54.5 s\n",
      "Wall time: 54.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
       "              max_depth=20, max_features=None, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=9,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=90,\n",
       "              presort='auto', random_state=1, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modele_GB =GradientBoostingClassifier(n_estimators=90, learning_rate=0.10, max_depth=20, min_samples_split=9, random_state=1)\n",
    "%time modele_GB.fit(X_train[var], Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultat d'apprentissage' :  0.999927302867\n",
      "Resultat de validation :  0.847177555679\n"
     ]
    }
   ],
   "source": [
    "print \"Resultat d'apprentissage' : \",validation(modele_GB, X_train[var], Y_train)\n",
    "print \"Resultat de validation : \",validation(modele_GB, X_test[var], Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Resultat d'apprentissage' :  0.999927302867\n",
    "    Resultat de validation :  0.851872455637\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/><br/><h4><span style=\"color: #c36b0f;\">Selection des variables : Random Forest</span></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MGR_ID', 'ROLE_DEPTNAME', 'ROLE_FAMILY_DESC', 'ROLE_ROLLUP_2', 'RESOURCE', 'ROLE_TITLE', 'ROLE_FAMILY', 'ROLE_ROLLUP_1']\n"
     ]
    }
   ],
   "source": [
    "#Approche integree\n",
    "def random_forest_selection(X,Y,n_features):\n",
    "    \n",
    "    params = {'max_depth':[13],\n",
    "              'min_samples_leaf' : [13]}\n",
    "    metric = 'roc_auc'\n",
    "    \n",
    "    clf = RandomForestClassifier(random_state=1, n_jobs=3)\n",
    "    gs = GridSearchCV(clf, params, scoring=metric)\n",
    "    gs.fit(X,Y)\n",
    "    bestClf = gs.best_estimator_\n",
    "    rf = bestClf.feature_importances_\n",
    "    \n",
    "    rf=zip(rf,X.columns)\n",
    "    rf=sorted(rf,reverse=True)[:n_features]\n",
    " \n",
    "    return [x[1] for x in rf]\n",
    "\n",
    "rfFeatures = random_forest_selection(X_train[var], Y_train,8)\n",
    "\n",
    "print rfFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color: #c36b0f;\">LogisticRegression</span></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xt : (32769, 10479)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from scipy import sparse\n",
    "\n",
    "#good_features=range(0,15283)\n",
    "Xt=OneHotEncoder().fit_transform(X[['MGR_ID', 'ROLE_DEPTNAME', 'ROLE_FAMILY_DESC', 'ROLE_ROLLUP_2', 'RESOURCE', 'ROLE_TITLE']].astype(str))\n",
    "print \"Xt :\", Xt.shape\n",
    "#Xts=sparse.hstack([Xt[:,j] for j in good_features]).tocsr()\n",
    "#print \"Xts :\", Xts.shape\n",
    "X_train_sparce, X_test_sparce, Y_train_sparce, Y_test_sparce = train_test_split(Xt, Y, test_size=0.25,random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=2.601, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=2.11, max_iter=100, multi_class='ovr',\n",
       "          n_jobs=2, penalty='l2', random_state=1, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modele_LR = linear_model.LogisticRegression(C=2.601, n_jobs=2, intercept_scaling=2.11, random_state=1)\n",
    "modele_LR.fit(X_train_sparce, Y_train_sparce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultat de validation :  0.859862978103\n",
      "Resultat de validation :  0.859862978103 C=2.601  intercept_scaling=2.11\n"
     ]
    }
   ],
   "source": [
    "print \"Resultat de validation : \",validation(modele_LR, X_test_sparce, Y_test_sparce)\n",
    "print \"Resultat de validation : \",0.859862978103, \"C=2.601\" ,\" intercept_scaling=2.11\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score  0.858838666775\n"
     ]
    }
   ],
   "source": [
    "print \"score \",0.858838666775"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "def getScoreClf(DF , Y , clf ):\n",
    "    #clf = clone(clf)\n",
    "    return max(cross_val_score(clf , DF , Y , scoring='roc_auc' ,  cv = 5 , n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.841066004837\n"
     ]
    }
   ],
   "source": [
    "print getScoreClf(X_test_sparce,Y_test_sparce,modele_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color: #c36b0f;\">Naive Bayes</span></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.1 ms, sys: 2.74 ms, total: 14.8 ms\n",
      "Wall time: 14.1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=0.041, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modele_NB = naive_bayes.BernoulliNB(alpha=0.041)\n",
    "%time modele_NB.fit(X_train_sparce, Y_train_sparce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultat de validation :  0.839242216379\n",
      "Resultat de validation :  0.839242216379   (alpha=0.041, binarize=0.0, class_prior=None, fit_prior=True)\n"
     ]
    }
   ],
   "source": [
    "print \"Resultat de validation : \",validation(modele_NB, X_test_sparce, Y_test_sparce)\n",
    "print \"Resultat de validation : \",0.839242216379, \"  (alpha=0.041, binarize=0.0, class_prior=None, fit_prior=True)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Soft VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Training classifiers\n",
    "\n",
    "#, ('LR', modele_LR), ('NB', modele_NB)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('DT', Modele_3.best_estimator_), ('RF', modele_RF), ('ABC', modele_ABC), ('XT', modele_XT), ('GB', modele_GB)], voting='soft', \n",
    "                        weights=[1,4,5,3,2])\n",
    "\n",
    "%time eclf = eclf.fit(X_train[var], Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Resultat de validation = \",validation(eclf, X_test[var], Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#regroupe les modalités des variables rares, pour un seuil donné \n",
    "def regroupe(df, column, seuil):\n",
    "    \n",
    "    #Valeurs les plus communes\n",
    "    ss = pd.DataFrame(data=df[column].value_counts())\n",
    "    selected = ss[column][ss[column]==1]\n",
    "    column_num = df.columns.get_loc(column)\n",
    "    for x in np.array(selected.index) :\n",
    "        for line_num in df[column][df[column]==x].index.values:\n",
    "            df.set_value(line_num, column_num, np.array(selected.index)[0], takeable=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regroupe(df, \"RESOURCE\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = eclf.predict_proba(test[var])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submissions = pd.DataFrame(data=preds, columns=[\"ACTION\"], index = test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submissions.to_csv(\"sampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Approche filtre\n",
    "def variance_selection(X,n_features):\n",
    "    \n",
    "    variance = [np.var(X.getcol(i).todense()) for i in range(X.shape[1])]\n",
    "    variance = sorted( zip(variance,range(X.shape[1])) ,reverse=True)[:n_features]   \n",
    "        \n",
    "    return [x[1] for x in variance]\n",
    "\n",
    "for n_features in range(1000,X.shape[1],100):\n",
    "    print n_features\n",
    "    good_features = variance_selection(X_train_sparce,n_features)\n",
    "    print 'Selected features : ', good_features\n",
    "    Xts=sparse.hstack([X_train_sparce[:,j] for j in good_features]).tocsr()\n",
    "    gs = performance(Xts, Y_train_sparce)\n",
    "    print gs.best_score_, gs.best_params_\n",
    "    \n",
    "    print '***************************\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
