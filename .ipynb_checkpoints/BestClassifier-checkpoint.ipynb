{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import (AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import metrics, linear_model, naive_bayes\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from scipy import sparse\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Chargement du fichier train.csv dans le dataframe df\n",
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fonction d'apprentissage avec cross validation et gridsearch sur le premier dataset\n",
    "def performance(X,Y):\n",
    "    kf = StratifiedKFold(Y, n_folds=3, random_state=1)    \n",
    "    gs = GridSearchCV(clf, params, scoring=metric, cv=kf)\n",
    "    gs.fit(X,Y)\n",
    "    return gs\n",
    "\n",
    "#fonction de prédiction sur le dataset de validation\n",
    "def validation(clf1, Xv, Yv):\n",
    "    preds = clf1.predict_proba(Xv)[:,1]\n",
    "    return roc_auc_score(Yv, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#regroupe les modalités des variables rares, pour un seuil donné \n",
    "def regroupe(df, column, seuil):\n",
    "    df_temp=df.copy()\n",
    "    if seuil==0:\n",
    "        return df_temp\n",
    "    else:\n",
    "        #if (df_temp[column].count()*2.5/100) <= (np.array(df_temp[column].value_counts()==seuil ,dtype=int).sum()):\n",
    "        #Valeurs les plus communes\n",
    "        ss = pd.DataFrame(data=df_temp[column].value_counts())\n",
    "        selected = ss[column][ss[column]<=seuil]\n",
    "        column_num = df_temp.columns.get_loc(column)\n",
    "        for x in np.array(selected.index) :\n",
    "            for line_num in df_temp[column][df_temp[column]==x].index.values:\n",
    "                df_temp.set_value(line_num, column_num, np.array(selected.index)[0], takeable=True)\n",
    "        #print column,\"seuil=\",seuil\n",
    "        return df_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Echantillonnage de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Y, X, X_train, X_test, Y_train, Y_test = \"\"\n",
    "\n",
    "def splitData(df):\n",
    "    Y = df.ACTION\n",
    "    X = df.drop(['ACTION'], axis=1)\n",
    "\n",
    "    # diviser X et Y en training and testing\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "    return  train_test_split(X, Y, test_size=0.25,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = splitData(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#b36c8f\">On supprime la colonne 'ROLE_CODE' et on garde 'ROLE_TITLE' <br/>(celle qui nous donne une meilleure score)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var=['RESOURCE', 'MGR_ID', 'ROLE_ROLLUP_1', 'ROLE_ROLLUP_2','ROLE_DEPTNAME', 'ROLE_TITLE', 'ROLE_FAMILY_DESC', 'ROLE_FAMILY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les arbres de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CHOIX DU MODELE A UTILISER\n",
    "#Les arbres de décision\n",
    "\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=1)\n",
    "params = {'max_depth':[13],\n",
    "          'min_samples_leaf' : [13]} #pour le gridSearch    \n",
    "metric = 'roc_auc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultat sur l'ensembles des données\n",
      "Resultat d'apprentissage :  0.71868130686 {'max_depth': 13, 'min_samples_leaf': 13}\n",
      "Resultat de validation :  0.779711035795\n"
     ]
    }
   ],
   "source": [
    "Modele_3 = performance(X_train[var],Y_train)\n",
    "print \"Resultat sur l'ensembles des données\"\n",
    "\n",
    "print \"Resultat d'apprentissage : \",Modele_3.best_score_, Modele_3.best_params_\n",
    "\n",
    "print \"Resultat de validation : \",validation(Modele_3.best_estimator_, X_test[var], Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = regroupe(df, \"RESOURCE\", 1)\n",
    "temp = regroupe(temp, \"ROLE_TITLE\", 0)\n",
    "temp = regroupe(temp, \"MGR_ID\", 1)\n",
    "temp = regroupe(temp, \"ROLE_ROLLUP_2\", 2)\n",
    "temp = regroupe(temp, \"ROLE_FAMILY_DESC\", 24)\n",
    "temp = regroupe(temp, \"ROLE_FAMILY\", 16)\n",
    "temp = regroupe(temp, \"ROLE_DEPTNAME\", 52)\n",
    "temp = regroupe(temp, \"ROLE_ROLLUP_1\", 5)\n",
    "Xr_train, Xr_test, Yr_train, Yr_test = splitData(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.1 s, sys: 812 ms, total: 43.9 s\n",
      "Wall time: 15.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=9,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1040, n_jobs=-1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modele_RF =RandomForestClassifier(n_estimators=1040, min_samples_split=9, n_jobs=-1, random_state=42)\n",
    "%time modele_RF.fit(Xr_train[var], Yr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultat d'apprentissage :  0.993743210163\n",
      "Resultat de validation :  0.873741614254\n"
     ]
    }
   ],
   "source": [
    "print \"Resultat d'apprentissage : \",validation(modele_RF, Xr_train[var], Yr_train)\n",
    "print \"Resultat de validation : \",validation(modele_RF, Xr_test[var], Yr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.873741614254   1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "## AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43min 16s, sys: 1min 44s, total: 45min 1s\n",
      "Wall time: 16min 44s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=9,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1040, n_jobs=-1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "          learning_rate=1.0, n_estimators=50, random_state=1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modele_ABC = AdaBoostClassifier(base_estimator = modele_RF, random_state=1, learning_rate=1.0)\n",
    "%time modele_ABC.fit(Xr_train[var], Yr_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%time print \"Resultat d'apprentissage' : \",validation(modele_ABC, X_train[var], Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultat de validation :  0.868794967295\n",
      "CPU times: user 2min 22s, sys: 1min 7s, total: 3min 29s\n",
      "Wall time: 2min 58s\n"
     ]
    }
   ],
   "source": [
    "%time print \"Resultat de validation : \",validation(modele_ABC, Xr_test[var], Yr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "## ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "temp = regroupe(df, \"RESOURCE\", 1)\n",
    "temp = regroupe(temp, \"RESOURCE\", 2)\n",
    "Xr_train, Xr_test, Yr_train, Yr_test = splitData(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.9 s, sys: 1.17 s, total: 32.1 s\n",
      "Wall time: 21.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_samples_leaf=1, min_samples_split=8,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=1020, n_jobs=-1,\n",
       "           oob_score=False, random_state=5, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modele_XT =ExtraTreesClassifier(n_estimators=1020, min_samples_split=8, n_jobs=-1, random_state=5)\n",
    "%time modele_XT.fit(Xr_train[var], Yr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultat d'apprentissage' :  0.994458806083\n",
      "Resultat de validation :  0.863034263857\n"
     ]
    }
   ],
   "source": [
    "print \"Resultat d'apprentissage' : \",validation(modele_XT, Xr_train[var], Yr_train)\n",
    "print \"Resultat de validation : \",validation(modele_XT, Xr_test[var], Yr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "## GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.2 s, sys: 345 ms, total: 43.6 s\n",
      "Wall time: 44.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(init=None, learning_rate=0.2, loss='deviance',\n",
       "              max_depth=20, max_features=None, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=9,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=90,\n",
       "              presort='auto', random_state=1, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modele_GB =GradientBoostingClassifier(n_estimators=90, learning_rate=0.20, max_depth=20, min_samples_split=9, random_state=1)\n",
    "%time modele_GB.fit(Xr_train[var], Yr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultat de validation :  0.858124917924\n"
     ]
    }
   ],
   "source": [
    "#print \"Resultat d'apprentissage' : \",validation(modele_GB, X_train[var], Y_train)\n",
    "print \"Resultat de validation : \",validation(modele_GB, Xr_test[var], Yr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = linear_model.LogisticRegression(C=2, intercept_scaling=1, random_state=1, n_jobs=-1)\n",
    "stkclf = StackingClassifier(classifiers=[modele_RF, modele_ABC, modele_XT, modele_GB], \n",
    "                          meta_classifier=lr, use_probas=True)\n",
    "%time stkclf = stkclf.fit(Xr_train[var], Yr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Resultat de validation = \",validation(stkclf, Xr_test[var], Yr_test)\n",
    "print \"Resultat de validation =  0.866552854297    C=2, intercept_scaling=1, random_state=1, n_jobs=-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soft VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 54s, sys: 7.69 s, total: 6min 2s\n",
      "Wall time: 2min 23s\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Training classifiers\n",
    "\n",
    "#, ('LR', modele_LR), ('NB', modele_NB)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('DT', Modele_3.best_estimator_), ('RF', modele_RF), ('ABC', modele_ABC), ('XT', modele_XT), ('GB', modele_GB)], voting='soft', \n",
    "                        weights=[1,19,30,3,2])\n",
    "%time eclf = eclf.fit(X_train[var], Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultat de validation =  0.87118600499\n"
     ]
    }
   ],
   "source": [
    "print \"Resultat de validation = \",validation(eclf, X_test[var], Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "0.871101763347  [1,10,20,3,2]\n",
    "0.87118600499   [1,19,30,3,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df=pd.DataFrame(columns=['DT','RF','ABC','XT','GB'])\n",
    "pred_df['DT']=Modele_3.best_estimator_.predict_proba(X_test[var])[:,1]\n",
    "pred_df['RF']=modele_RF.predict_proba(X_test[var])[:,1]\n",
    "pred_df['ABC']=modele_ABC.predict_proba(X_test[var])[:,1]\n",
    "pred_df['XT']=modele_XT.predict_proba(X_test[var])[:,1]\n",
    "pred_df['GB']=modele_GB.predict_proba(X_test[var])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ridge_selection(pred_df,Y):\n",
    "    \n",
    "    cols = pred__df.columns\n",
    "    #pred_df=StandardScaler().fit_transform(pred_df)\n",
    "\n",
    "    params = {'alpha':[0.5, 0.21, 0.01,0.05, 0.1, 0.2, 1, 0.3, 0.4, 0.6, 0.7, 2]}\n",
    "    metric = 'roc_auc'\n",
    "    clf = Ridge(random_state=1)\n",
    "    kf = StratifiedKFold(Y, n_folds=3, random_state=1)   \n",
    "    gs = GridSearchCV(clf, params, scoring=metric, cv=kf)\n",
    "    gs.fit(pred_df,Y)\n",
    "    ls = gs.best_estimator_.coef_\n",
    "    print gs.best_params_\n",
    "    ls=zip(ls,cols)\n",
    "    #ls=sorted(ls,reverse=True)\n",
    " \n",
    "    return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 2}\n"
     ]
    }
   ],
   "source": [
    "rest = ridge_selection(pred_df,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.089336644538873036, 0.43357372603901401, 0.2690017101145214, 0.15125205394428781, 0.15775743806230372]\n"
     ]
    }
   ],
   "source": [
    "print [rest[i][0] for i in range(len(rest))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def recur(data,Y, clf, seuil, nb_col, cont, liste_seuil, ListeScore, lim, coef):\n",
    "    if nb_col < len(goodVar)-1:\n",
    "        for i in range(seuil):\n",
    "            liste_seuil[nb_col]=i\n",
    "            tmp1 = regroupe(data, goodVar[nb_col], i)\n",
    "            recur(tmp1,Y, clf, seuil, nb_col+1, cont+1, liste_seuil, ListeScore, lim, coef)\n",
    "    else :\n",
    "        for n in range(seuil):\n",
    "            liste_seuil[nb_col]=n\n",
    "            tmp1 = regroupe(data, goodVar[nb_col], n)\n",
    "            tmp = OneHotEncoder().fit_transform(tmp1[goodVar].astype(str))\n",
    "            X_train_all = tmp[:len(Y),:]\n",
    "            X_train_sparce, X_test_sparce, Y_train_sparce, Y_test_sparce = train_test_split(X_train_all, Y, test_size=0.25,random_state=1)\n",
    "            clf.fit(X_train_sparce, Y_train_sparce)\n",
    "            score = validation(clf, X_test_sparce, Y_test_sparce)\n",
    "            if n == seuil-1:\n",
    "                cl=(cont/lim)\n",
    "                if cl > coef:\n",
    "                    print \"Complete ...   %.2f \"%cl,\"%\"\n",
    "                    coef=coef+1.0\n",
    "                    print max(ListeScore)\n",
    "            ls = [score,liste_seuil]\n",
    "            ListeScore.append(ls)\n",
    "            \n",
    "\n",
    "    return ListeScore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bestSeuilRecur(data,Y, clf, goodVar, seuilLim):\n",
    "    seuil = seuilLim +1\n",
    "    lim = (((1 - pow(seuil,len(goodVar)+1)) / ( 1 - seuil )*1.0) - 1)/100.0\n",
    "    ListeScore = []\n",
    "    cl=0.0\n",
    "    cont=0.0\n",
    "    coef=1.0\n",
    "    nb_col=0\n",
    "    liste_seuil=[0]*(len(goodVar))\n",
    "    allScores = recur(data,Y, clf, seuil, nb_col, cont, liste_seuil, ListeScore,lim,coef)\n",
    "    print \"Best Score : \",max(allScores)\n",
    "    return allScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def totalBestSeuil(data,Y, clf, goodVar, seuilLim):\n",
    "    seuil = seuilLim +1\n",
    "    lim = (((1 - pow(seuil,len(goodVar)+1)) / ( 1 - seuil )*1.0) - 1)/100.0\n",
    "    ListeScore = []\n",
    "    cl=0.0\n",
    "    cont=0.0\n",
    "    coef=1.0\n",
    "    for i in range(seuil):\n",
    "        cont=cont+1.0\n",
    "        tmp1 = regroupe(data, goodVar[0], i)\n",
    "        for j in range(seuil):\n",
    "            cont=cont+1.0\n",
    "            tmp2 = regroupe(tmp1, goodVar[1], j)\n",
    "            for k in range(seuil):\n",
    "                cont=cont+1.0\n",
    "                tmp3 = regroupe(tmp2, goodVar[2], k)\n",
    "                for l in range(seuil):\n",
    "                    cont=cont+1.0\n",
    "                    tmp4 = regroupe(tmp3, goodVar[3], l)\n",
    "                    for ll in range(seuil):\n",
    "                        cont=cont+1.0\n",
    "                        tmp41 = regroupe(tmp4, goodVar[4], ll)\n",
    "                        for lll in range(seuil):\n",
    "                            cont=cont+1.0\n",
    "                            tmp42 = regroupe(tmp41, goodVar[5], lll)\n",
    "                            for m in range(seuil):\n",
    "                                cont=cont+1.0\n",
    "                                tmp5 = regroupe(tmp42, goodVar[6], m)\n",
    "                                for n in range(seuil):\n",
    "                                    cont=cont+1.0\n",
    "                                    tmp6 = regroupe(tmp5, goodVar[7], n)\n",
    "                                    tmp = OneHotEncoder().fit_transform(tmp6[goodVar].astype(str))\n",
    "                                    X_train_all = tmp[:len(Y),:]\n",
    "                                    X_train_sparce, X_test_sparce, Y_train_sparce, Y_test_sparce = train_test_split(X_train_all, Y, test_size=0.25,random_state=1)\n",
    "                                    clf.fit(X_train_sparce, Y_train_sparce)\n",
    "                                    score = validation(clf, X_test_sparce, Y_test_sparce)\n",
    "                                    if n == seuil-1:\n",
    "                                        cl=(cont/lim)\n",
    "                                        if cl > coef:\n",
    "                                            print \"Complete ...   %.2f \"%cl,\"%\"\n",
    "                                            coef=coef+1.0\n",
    "                                            print max(ListeScore)\n",
    "                                    ls = [score,i,j,k,l,ll,lll,m,n]\n",
    "                                    ListeScore.append(ls)\n",
    "    print \"Best Score : \",max(ListeScore)                \n",
    "    return ListeScore\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bestSeuil(data,Y, clf, goodVar, seuilLim):\n",
    "    seuil = seuilLim +1\n",
    "    lim = (((1 - pow(seuil,len(goodVar)+1)) / ( 1 - seuil )*1.0) - 1)/100.0\n",
    "    ListeScore = []\n",
    "    cl=0.0\n",
    "    cont=0.0\n",
    "    coef=1.0\n",
    "    for i in range(seuil):\n",
    "        cont=cont+1.0\n",
    "        tmp1 = regroupe(data, goodVar[0], i)\n",
    "        for j in range(seuil):\n",
    "            cont=cont+1.0\n",
    "            tmp2 = regroupe(tmp1, goodVar[1], j)\n",
    "            for k in range(seuil):\n",
    "                cont=cont+1.0\n",
    "                tmp3 = regroupe(tmp2, goodVar[2], k)\n",
    "                for l in range(seuil):\n",
    "                    cont=cont+1.0\n",
    "                    tmp4 = regroupe(tmp3, goodVar[3], l)\n",
    "                    for m in range(seuil):\n",
    "                        cont=cont+1.0\n",
    "                        tmp5 = regroupe(tmp4, goodVar[4], m)\n",
    "                        for n in range(seuil):\n",
    "                            cont=cont+1.0\n",
    "                            tmp6 = regroupe(tmp5, goodVar[5], n)\n",
    "                            tmp = OneHotEncoder().fit_transform(tmp6[goodVar].astype(str))\n",
    "                            X_train_all = tmp[:len(Y),:]\n",
    "                            X_train_sparce, X_test_sparce, Y_train_sparce, Y_test_sparce = train_test_split(X_train_all, Y, test_size=0.25,random_state=1)\n",
    "                            clf.fit(X_train_sparce, Y_train_sparce)\n",
    "                            score = validation(clf, X_test_sparce, Y_test_sparce)\n",
    "                            if n == seuil-1:\n",
    "                                cl=(cont/lim)\n",
    "                                if cl > coef:\n",
    "                                    print \"Complete ...   %.2f \"%cl,\"%\"\n",
    "                                    coef=coef+1.0\n",
    "                                    print max(ListeScore)\n",
    "                            ls = [score,i,j,k,l,m,n]\n",
    "                            ListeScore.append(ls)\n",
    "    print \"Best Score : \",max(ListeScore)                \n",
    "    return ListeScore\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%time BS=totalBestSeuil(df, modele_LR, df.columns.values[1:-1], 1)\n",
    "orders= ['ROLE_ROLLUP_2', 'RESOURCE', 'ROLE_TITLE','MGR_ID', 'ROLE_DEPTNAME', 'ROLE_FAMILY_DESC']\n",
    "#%time BS=bestSeuil(all_data, Y, modele_LR, orders, 3)\n",
    "#%time BS10=bestSeuil(all_data, Y, modele_NB, orders, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modele_XT =ExtraTreesClassifier(n_estimators=1020, min_samples_split=8, n_jobs=-1, random_state=5)\n",
    "#%time XT=totalBestSeuil(all_data,Y, modele_LR, var, 1)\n",
    "#%time XTr=bestSeuilRecur(all_data,Y, modele_LR, var, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_all :  (91690, 13295)\n",
      "0.875546173641\n"
     ]
    }
   ],
   "source": [
    "tempxt = regroupe(all_data, var[0], 1)\n",
    "tempxt = regroupe(tempxt, var[1], 0)\n",
    "tempxt = regroupe(tempxt, var[2], 1)\n",
    "tempxt = regroupe(tempxt, var[3], 1)\n",
    "tempxt = regroupe(tempxt, var[4], 0)\n",
    "tempxt = regroupe(tempxt, var[5], 1)\n",
    "tempxt = regroupe(tempxt, var[6], 0)\n",
    "tempxt = regroupe(tempxt, var[7], 1)\n",
    "\n",
    "\n",
    "X_all = OneHotEncoder().fit_transform(tempxt[var].astype(str))\n",
    "print \"X_all : \",X_all.shape\n",
    "\n",
    "X_train_all = X_all[:train_rows,:]\n",
    "X_test_all = X_all[train_rows:,:]\n",
    "\n",
    "X_train_sparce, X_test_sparce, Y_train_sparce, Y_test_sparce = train_test_split(X_train_all, Y, test_size=0.25,random_state=1)\n",
    "modele_XT.fit(X_train_sparce, Y_train_sparce)\n",
    "score = validation(modele_XT, X_test_sparce, Y_test_sparce)\n",
    "print score\n",
    "\n",
    "#0.876431479272"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg =  [0.84870403381959725, 674, 236]\n",
      "RL =  [0.85899443697803024, 0, 2, 2, 2, 0, 2]\n",
      "NB =  [0.83841363066116437, 0, 2, 2, 2, 0, 2]\n"
     ]
    }
   ],
   "source": [
    "bes=[0,0,0]\n",
    "for i in range(len(BS)):\n",
    "    for j in range(len(BS1)):\n",
    "        if BS[i][1]==BS1[j][1] and BS[i][2]==BS1[j][2] and BS[i][3]==BS1[j][3] and BS[i][4]==BS1[j][4] and BS[i][5]==BS1[j][5] and BS[i][6]==BS1[j][6]:\n",
    "            tm = (BS[i][0]+BS1[j][0])/2.0\n",
    "            if bes[0] < tm:\n",
    "                bes[0] = tm\n",
    "                bes[1] = i\n",
    "                bes[2] = j\n",
    "print \"avg = \",bes\n",
    "print \"RL = \",BS[bes[1]]\n",
    "print \"NB = \",BS1[bes[2]]\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Best Score :  [0.86015887163697025, 1, 2, 0, 0, 1, 1] RL ~ 20min\n",
    "        ['MGR_ID', 'ROLE_DEPTNAME', 'ROLE_FAMILY_DESC', 'ROLE_ROLLUP_2', 'RESOURCE', 'ROLE_TITLE']\n",
    "        \n",
    "    Best Score :  [0.86080123163238786, 3, 3, 3, 0, 1, 1] RL ~ 1h42min\n",
    "        ['MGR_ID', 'ROLE_DEPTNAME', 'ROLE_FAMILY_DESC', 'ROLE_ROLLUP_2', 'RESOURCE', 'ROLE_TITLE']\n",
    "    \n",
    "    Best Score :  [0.86013526162408949, 1, 1, 2, 0, 0, 0] RL ~ 3h22min\n",
    "        ['ROLE_ROLLUP_2'*1, 'RESOURCE'*1, 'ROLE_TITLE'*2,'MGR_ID'*0, 'ROLE_DEPTNAME'*0, 'ROLE_FAMILY_DESC'*0]\n",
    "        \n",
    "    Best Score :  [0.84153029206563856, 2, 2, 2, 1, 2, 2] NB ~ 17min\n",
    "        ['MGR_ID', 'ROLE_DEPTNAME', 'ROLE_FAMILY_DESC', 'ROLE_ROLLUP_2', 'RESOURCE', 'ROLE_TITLE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the inputs used:  ['RESOURCE' 'MGR_ID' 'ROLE_ROLLUP_1' 'ROLE_ROLLUP_2' 'ROLE_DEPTNAME'\n",
      " 'ROLE_TITLE' 'ROLE_FAMILY_DESC' 'ROLE_FAMILY']\n",
      "\n",
      "\n",
      "Combined test, train data rows and columns:  (91690, 8)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv', index_col=0)\n",
    "train = pd.read_csv('train.csv') \n",
    "input_cols = train.columns[1:-1] # don't need first (label) or last (duplicate)\n",
    "Y = train.ACTION\n",
    "print \"These are the inputs used: \",input_cols.values\n",
    "print \"\\n\"\n",
    "\n",
    "all_data = np.vstack((train[input_cols.values], test[input_cols.values]))\n",
    "train_rows = len(train)\n",
    "print \"Combined test, train data rows and columns: \",all_data.shape\n",
    "print \"\\n\"\n",
    "all_data=pd.DataFrame(data=all_data, columns=input_cols)\n",
    "\n",
    "goodVar= ['MGR_ID', 'ROLE_DEPTNAME', 'ROLE_FAMILY_DESC', 'ROLE_ROLLUP_2', 'RESOURCE', 'ROLE_TITLE']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_all :  (91690, 11338)\n",
      "(32769, 11338) == (58921, 11338)\n"
     ]
    }
   ],
   "source": [
    "#goodVar= ['MGR_ID', 'ROLE_DEPTNAME', 'ROLE_FAMILY_DESC', 'ROLE_ROLLUP_2', 'RESOURCE', 'ROLE_TITLE']\n",
    "\n",
    "#tempxt = regroupe(all_data,var[0],1)\n",
    "#tempxt = regroupe(tempxt, var[1], 0)\n",
    "#tempxt = regroupe(tempxt, var[2], 1)\n",
    "#tempxt = regroupe(tempxt, var[3], 1)\n",
    "#tempxt = regroupe(tempxt, var[4], 0)\n",
    "#tempxt = regroupe(tempxt, var[5], 1)\n",
    "#tempxt = regroupe(tempxt, var[6], 0)\n",
    "#tempxt = regroupe(tempxt, var[7], 1)\n",
    "\n",
    "\n",
    "temp = regroupe(all_data, \"RESOURCE\", 1)\n",
    "temp = regroupe(temp, \"ROLE_TITLE\", 0)\n",
    "temp = regroupe(temp, \"MGR_ID\", 1)\n",
    "temp = regroupe(temp, \"ROLE_ROLLUP_2\", 2)\n",
    "temp = regroupe(temp, \"ROLE_FAMILY_DESC\", 24)\n",
    "temp = regroupe(temp, \"ROLE_FAMILY\", 16)\n",
    "temp = regroupe(temp, \"ROLE_DEPTNAME\", 52)\n",
    "tempxt = regroupe(temp, \"ROLE_ROLLUP_1\", 5)\n",
    "\n",
    "\n",
    "\n",
    "#good_features=range(0,15283)\n",
    "\n",
    "X_all = OneHotEncoder().fit_transform(tempxt[var].astype(str))\n",
    "print \"X_all : \",X_all.shape\n",
    "\n",
    "#Xts=sparse.hstack([X_all[:,j] for j in good_features]).tocsr()\n",
    "\n",
    "\n",
    "X_train_all = X_all[:train_rows,:]\n",
    "X_test_all = X_all[train_rows:,:]\n",
    "print X_train_all.shape,\"==\",X_test_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_sparce, X_test_sparce, Y_train_sparce, Y_test_sparce = train_test_split(X_train_all, Y, test_size=0.25,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color: #c36b0f;\">LogisticRegression</span></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=2.601, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=2.11, max_iter=100, multi_class='ovr',\n",
       "          n_jobs=-1, penalty='l2', random_state=1, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modele_LR = linear_model.LogisticRegression(C=2.601, n_jobs=-1,intercept_scaling=2.11, random_state=1)\n",
    "modele_LR.fit(X_train_sparce, Y_train_sparce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultat de validation :  0.857960066946\n",
      "Resultat de validation :  0.859862978103\n"
     ]
    }
   ],
   "source": [
    "print \"Resultat de validation : \",validation(modele_LR, X_test_sparce, Y_test_sparce)\n",
    "print \"Resultat de validation :  0.859862978103\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color: #c36b0f;\">Naive Bayes</span></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.3 ms, sys: 3.09 ms, total: 17.4 ms\n",
      "Wall time: 16 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=0.041, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modele_NB = naive_bayes.BernoulliNB(alpha=0.041)\n",
    "%time modele_NB.fit(X_train_sparce, Y_train_sparce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultat de validation :  0.828233663687\n",
      "Resultat de validation :  0.839242216379\n"
     ]
    }
   ],
   "source": [
    "print \"Resultat de validation : \",validation(modele_NB, X_test_sparce, Y_test_sparce)\n",
    "print \"Resultat de validation :  0.839242216379\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color: #3366ff;\">Modèle : SVM</span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "Cs = [5, 6, 8, 9, 10]\n",
    "gammas = [ 0.1, 0.3, 0.4, 0.5, 0.6]\n",
    "metric = 'roc_auc'\n",
    "param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "\n",
    "kf = StratifiedKFold(Y_train_sparce, n_folds=3, random_state=1)   \n",
    "grid_search = GridSearchCV(SVC(probability=True, random_state=1), param_grid, scoring=metric, cv=kf)\n",
    "%time grid_search.fit(X_train_sparce, Y_train_sparce)\n",
    "print \"best_params = \",grid_search.best_params_,\"    best_score = \", grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "print \"Resultat de validation : \", validation(grid_search.best_estimator_, X_test_sparce, Y_test_sparce)\n",
    "print \"best_params =  {'C': 9, 'gamma': 0.5}    best_score =  0.854205877918  : 0.863020153731    Wall time: 3h 27min 27s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14min 20s, sys: 9.67 s, total: 14min 30s\n",
      "Wall time: 15min 17s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=9, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.5, kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=1, shrinking=True, tol=0.001,\n",
       "  verbose=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#modele_SVC = grid_search.best_estimator_\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "modele_SVC = SVC(probability=True, random_state=1, C= 9, gamma= 0.5)\n",
    "%time modele_SVC.fit(X_train_sparce, Y_train_sparce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultat de validation :  0.859536489345\n",
      "best_params =  {'C': 9, 'gamma': 0.5}   0.863145608118  [1, 1, 2, 0, 0, 0]orders  Wall time: 3h 27min 27s\n"
     ]
    }
   ],
   "source": [
    "print \"Resultat de validation : \", validation(modele_SVC, X_test_sparce, Y_test_sparce)\n",
    "print \"best_params =  {'C': 9, 'gamma': 0.5}   0.863145608118  [1, 1, 2, 0, 0, 0]orders  Wall time: 3h 27min 27s\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color: #3366ff;\">KNeighborsClassifier</span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "modele_KN = KNeighborsClassifier(n_neighbors=9, n_jobs=-1)\n",
    "modele_KN.fit(X_train_sparce, Y_train_sparce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%time print \"Resultat de validation : \",validation(modele_KN, X_test_sparce, Y_test_sparce)\n",
    "print \"Resultat de validation :  0.82623072431   n_neighbors=9\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.877152353038\n"
     ]
    }
   ],
   "source": [
    "modele_XT =ExtraTreesClassifier(n_estimators=1020, min_samples_split=8, n_jobs=-1, random_state=5)\n",
    "modele_XT.fit(X_train_sparce, Y_train_sparce)\n",
    "print validation(modele_XT, X_test_sparce, Y_test_sparce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modele_XT =ExtraTreesClassifier(n_estimators=1020, min_samples_split=8, n_jobs=-1, random_state=5)\n",
    "\n",
    "\n",
    "tempxt = regroupe(all_data, var[0], 1)\n",
    "tempxt = regroupe(tempxt, var[1], 0)\n",
    "tempxt = regroupe(tempxt, var[2], 1)\n",
    "tempxt = regroupe(tempxt, var[3], 1)\n",
    "tempxt = regroupe(tempxt, var[4], 0)\n",
    "tempxt = regroupe(tempxt, var[5], 1)\n",
    "tempxt = regroupe(tempxt, var[6], 0)\n",
    "tempxt = regroupe(tempxt, var[7], 1)\n",
    "\n",
    "\n",
    "X_all = OneHotEncoder().fit_transform(tempxt[var].astype(str))\n",
    "print \"X_all : \",X_all.shape\n",
    "\n",
    "X_train_all = X_all[:train_rows,:]\n",
    "X_test_all = X_all[train_rows:,:]\n",
    "\n",
    "X_train_sparce, X_test_sparce, Y_train_sparce, Y_test_sparce = train_test_split(X_train_all, Y, test_size=0.25,random_state=1)\n",
    "modele_XT.fit(X_train_sparce, Y_train_sparce)\n",
    "score = validation(modele_XT, X_test_sparce, Y_test_sparce)\n",
    "print score\n",
    "\n",
    "#0.876431479272"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ExtraTreesClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-31d8140e86c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mXT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExtraTreesClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"entropy\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time XT.fit(Xr_train[var], Yr_train)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_sparce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test_sparce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ExtraTreesClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "XT = ExtraTreesClassifier(n_estimators=200, min_samples_split=5, min_samples_leaf=0.01,criterion=\"entropy\" , n_jobs=-1, random_state=5)\n",
    "%time XT.fit(Xr_train[var], Yr_train)\n",
    "print validation(XT, X_test_sparce, Y_test_sparce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43min 26s, sys: 7.77 s, total: 43min 34s\n",
      "Wall time: 20min 51s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "sclf = VotingClassifier(estimators=[('NB', modele_NB), ('LR', modele_LR), ('SVC', modele_SVC), ('XT', modele_XT)], voting='soft', \n",
    "                        weights=[1,15.1111,10,35])\n",
    "\n",
    "%time sclf = sclf.fit(X_train_sparce, Y_train_sparce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultat de validation =  0.877723184474\n",
      "\n",
      "\n",
      "Resultat de validation =  0.877450062727  weights=[1,10.1111,23]  \n",
      "RESOURCE seuil= 1 | RESOURCE seuil= 2 | MGR_ID seuil= 1\n",
      "Wall time: 12min 7s\n"
     ]
    }
   ],
   "source": [
    "print \"Resultat de validation = \",validation(sclf, X_test_sparce, Y_test_sparce)\n",
    "print \"\\n\\nResultat de validation = \",0.877450062727,\" weights=[1,10.1111,23] \",\"\\nRESOURCE seuil= 1 | RESOURCE seuil= 2 | MGR_ID seuil= 1\\nWall time: 12min 7s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Resultat de validation =  0.877723184474  weights=[1,15.1111,10,35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit Cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv', index_col=0)\n",
    "preds = eclf.predict_proba(test[var])[:,1]\n",
    "submissions = pd.DataFrame(data=preds, columns=[\"ACTION\"], index = test.index)\n",
    "submissions.to_csv(\"sampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit Num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = sclf.predict_proba(X_test_all)[:,1]\n",
    "submissions = pd.DataFrame(data=preds, columns=[\"ACTION\"], index = test.index)\n",
    "submissions.to_csv(\"sampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
